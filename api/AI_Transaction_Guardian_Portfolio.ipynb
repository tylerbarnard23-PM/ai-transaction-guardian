{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d06d4b0",
   "metadata": {},
   "source": [
    "\n",
    "# ðŸ›¡ï¸ AI Transaction Guardian â€“ Portfolio Notebook\n",
    "\n",
    "This notebook demonstrates an end-to-end **transaction risk scoring / fraud detection** workflow suitable for a product portfolio project.\n",
    "\n",
    "It includes:\n",
    "\n",
    "1. Data loading (with a fallback synthetic dataset if no CSV is available)\n",
    "2. Exploratory data analysis (EDA)\n",
    "3. Feature engineering & preprocessing\n",
    "4. Model training (Logistic Regression + Random Forest)\n",
    "5. Evaluation (ROC-AUC, precision/recall, confusion matrix)\n",
    "6. Threshold tuning\n",
    "7. A reusable **`score_transactions`** function to generate risk scores for new data\n",
    "\n",
    "> ðŸ”§ **TODO (when you wire this to real data):**  \n",
    "> - Point `DATA_PATH` at your real transaction CSV  \n",
    "> - Align column names & data types with your production schema\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f95bc673",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Core imports\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Modeling & evaluation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    precision_recall_curve\n",
    ")\n",
    "\n",
    "import joblib\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de7f7a4a",
   "metadata": {},
   "source": [
    "## 1. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23121694",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Path to your real transaction CSV\n",
    "# Example expected columns (customize as needed):\n",
    "# - transaction_id\n",
    "# - customer_id\n",
    "# - amount\n",
    "# - merchant_category\n",
    "# - channel (e.g., 'ecom', 'pos', 'ivr')\n",
    "# - country\n",
    "# - is_fraud (0/1 label)\n",
    "DATA_PATH = \"data/transactions.csv\"  # <-- Update this to your real path\n",
    "\n",
    "def load_or_generate_data(path: str, n_rows: int = 5000, random_state: int = 42) -> pd.DataFrame:\n",
    "    \"\"\"Load a CSV if it exists, otherwise generate a synthetic dataset.\"\"\"\n",
    "    if os.path.exists(path):\n",
    "        print(f\"âœ… Loading real data from: {path}\")\n",
    "        df = pd.read_csv(path)\n",
    "        return df\n",
    "    \n",
    "    print(\"âš ï¸ No CSV found, generating synthetic demo data instead...\")\n",
    "    rng = np.random.default_rng(random_state)\n",
    "    \n",
    "    n = n_rows\n",
    "    df = pd.DataFrame({\n",
    "        \"transaction_id\": np.arange(1, n + 1),\n",
    "        \"customer_id\": rng.integers(1, 1000, size=n),\n",
    "        \"amount\": np.round(rng.gamma(shape=2.0, scale=40.0, size=n), 2),\n",
    "        \"merchant_category\": rng.choice(\n",
    "            [\"grocery\", \"electronics\", \"travel\", \"gaming\", \"restaurants\", \"gas\"], \n",
    "            size=n, \n",
    "            replace=True\n",
    "        ),\n",
    "        \"channel\": rng.choice([\"ecom\", \"pos\", \"ivr\", \"mobile\"], size=n, replace=True),\n",
    "        \"country\": rng.choice([\"US\", \"CA\", \"GB\", \"AU\", \"DE\"], size=n, replace=True),\n",
    "    })\n",
    "    \n",
    "    # Create a synthetic fraud pattern\n",
    "    base_prob = 0.03\n",
    "    prob = np.full(n, base_prob)\n",
    "    \n",
    "    # Higher risk patterns\n",
    "    prob += np.where(df[\"amount\"] > 250, 0.04, 0.0)\n",
    "    prob += np.where(df[\"merchant_category\"].isin([\"electronics\", \"travel\", \"gaming\"]), 0.03, 0.0)\n",
    "    prob += np.where(df[\"channel\"].isin([\"ecom\", \"mobile\"]), 0.02, 0.0)\n",
    "    prob += np.where(df[\"country\"].isin([\"GB\", \"DE\"]), 0.01, 0.0)\n",
    "    \n",
    "    prob = np.clip(prob, 0, 0.95)\n",
    "    df[\"is_fraud\"] = rng.binomial(1, prob)\n",
    "    \n",
    "    print(\"âœ… Synthetic dataset created with shape:\", df.shape)\n",
    "    print(\"Fraud rate:\", df[\"is_fraud\"].mean())\n",
    "    return df\n",
    "\n",
    "df = load_or_generate_data(DATA_PATH)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbea6154",
   "metadata": {},
   "source": [
    "## 2. Quick EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e37b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"Shape:\", df.shape)\n",
    "print(\"\\nColumns:\", df.columns.tolist())\n",
    "\n",
    "print(\"\\nClass balance (is_fraud):\")\n",
    "print(df[\"is_fraud\"].value_counts(normalize=True).rename(\"proportion\"))\n",
    "\n",
    "print(\"\\nAmount stats:\")\n",
    "print(df[\"amount\"].describe())\n",
    "\n",
    "print(\"\\nMerchant category counts:\")\n",
    "print(df[\"merchant_category\"].value_counts().head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a69761d6",
   "metadata": {},
   "source": [
    "## 3. Feature engineering & preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac939e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define features and target\n",
    "TARGET_COL = \"is_fraud\"\n",
    "\n",
    "# Keep a simple feature set for now; customize for real project\n",
    "numeric_features = [\"amount\"]\n",
    "categorical_features = [\"merchant_category\", \"channel\", \"country\"]\n",
    "\n",
    "feature_cols = numeric_features + categorical_features\n",
    "\n",
    "df_model = df[feature_cols + [TARGET_COL]].dropna()\n",
    "\n",
    "X = df_model[feature_cols]\n",
    "y = df_model[TARGET_COL]\n",
    "\n",
    "print(\"Modeling dataset shape:\", X.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde1d9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(\"Train shape:\", X_train.shape)\n",
    "print(\"Test shape:\", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb4e4327",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Preprocess numeric + categorical features\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "        (\"cat\", categorical_transformer, categorical_features),\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af3bb669",
   "metadata": {},
   "source": [
    "## 4. Train models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b792ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Logistic Regression pipeline\n",
    "log_reg_pipeline = Pipeline(steps=[\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"model\", LogisticRegression(max_iter=1000, class_weight=\"balanced\"))\n",
    "])\n",
    "\n",
    "# Random Forest pipeline\n",
    "rf_pipeline = Pipeline(steps=[\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"model\", RandomForestClassifier(\n",
    "        n_estimators=200,\n",
    "        max_depth=None,\n",
    "        min_samples_split=2,\n",
    "        min_samples_leaf=1,\n",
    "        n_jobs=-1,\n",
    "        class_weight=\"balanced_subsample\",\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "models = {\n",
    "    \"log_reg\": log_reg_pipeline,\n",
    "    \"random_forest\": rf_pipeline\n",
    "}\n",
    "\n",
    "fitted_models = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nðŸš€ Training model: {name}\")\n",
    "    model.fit(X_train, y_train)\n",
    "    fitted_models[name] = model\n",
    "    \n",
    "    # Evaluate quickly on test set\n",
    "    y_proba = model.predict_proba(X_test)[:, 1]\n",
    "    auc = roc_auc_score(y_test, y_proba)\n",
    "    print(f\"AUC ({name}): {auc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4eae2f9",
   "metadata": {},
   "source": [
    "## 5. Detailed evaluation for champion model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34554a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Choose champion model here\n",
    "champion_name = \"random_forest\"  # change to \"log_reg\" if you prefer\n",
    "champion_model = fitted_models[champion_name]\n",
    "\n",
    "print(f\"Using champion model: {champion_name}\")\n",
    "\n",
    "y_proba = champion_model.predict_proba(X_test)[:, 1]\n",
    "y_pred_default = (y_proba >= 0.5).astype(int)\n",
    "\n",
    "print(\"\\nAUC:\", roc_auc_score(y_test, y_proba))\n",
    "print(\"\\nClassification report (threshold=0.5):\")\n",
    "print(classification_report(y_test, y_pred_default))\n",
    "\n",
    "print(\"\\nConfusion matrix (threshold=0.5):\")\n",
    "print(confusion_matrix(y_test, y_pred_default))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc6b33b",
   "metadata": {},
   "source": [
    "## 6. Threshold tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d194786e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, y_proba)\n",
    "\n",
    "# Example strategy: pick threshold that gives at least target_recall\n",
    "target_recall = 0.80\n",
    "best_threshold = 0.5\n",
    "best_precision = 0\n",
    "best_recall = 0\n",
    "\n",
    "for p, r, t in zip(precision, recall, np.append(thresholds, 1.0)):\n",
    "    if r >= target_recall and p > best_precision:\n",
    "        best_precision = p\n",
    "        best_recall = r\n",
    "        best_threshold = t\n",
    "\n",
    "print(f\"Chosen threshold: {best_threshold:.4f}\")\n",
    "print(f\"Precision at chosen threshold: {best_precision:.4f}\")\n",
    "print(f\"Recall at chosen threshold: {best_recall:.4f}\")\n",
    "\n",
    "# Evaluate at chosen threshold\n",
    "y_pred_tuned = (y_proba >= best_threshold).astype(int)\n",
    "print(\"\\nClassification report (tuned threshold):\")\n",
    "print(classification_report(y_test, y_pred_tuned))\n",
    "\n",
    "print(\"\\nConfusion matrix (tuned threshold):\")\n",
    "print(confusion_matrix(y_test, y_pred_tuned))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d70678d",
   "metadata": {},
   "source": [
    "## 7. Scoring function for new transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b30e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def score_transactions(\n",
    "    df_new: pd.DataFrame,\n",
    "    model: Pipeline,\n",
    "    threshold: float,\n",
    "    id_col: str = \"transaction_id\"\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"Score new transactions and flag those above a risk threshold.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df_new : pd.DataFrame\n",
    "        New transactions. Must contain the same feature columns used in training.\n",
    "    model : Pipeline\n",
    "        Fitted sklearn Pipeline with a `predict_proba` method.\n",
    "    threshold : float\n",
    "        Risk score threshold above which to flag transactions.\n",
    "    id_col : str\n",
    "        Column name to treat as primary key / transaction identifier.\n",
    "    \"\"\"\n",
    "    missing_cols = [c for c in feature_cols if c not in df_new.columns]\n",
    "    if missing_cols:\n",
    "        raise ValueError(f\"df_new is missing required columns: {missing_cols}\")\n",
    "    \n",
    "    X_new = df_new[feature_cols]\n",
    "    scores = model.predict_proba(X_new)[:, 1]\n",
    "    flags = (scores >= threshold).astype(int)\n",
    "    \n",
    "    out = df_new.copy()\n",
    "    out[\"risk_score\"] = scores\n",
    "    out[\"is_flagged\"] = flags\n",
    "    return out[[id_col] + feature_cols + [\"risk_score\", \"is_flagged\"]] if id_col in out.columns else out\n",
    "\n",
    "# Demo with a few rows from the test set\n",
    "demo = X_test.copy().head(5)\n",
    "demo[\"transaction_id\"] = np.arange(1, len(demo) + 1)\n",
    "scored_demo = score_transactions(demo, champion_model, best_threshold)\n",
    "scored_demo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e4e880",
   "metadata": {},
   "source": [
    "## 8. Persist champion model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b5531b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "MODEL_PATH = \"models/ai_transaction_guardian_champion.joblib\"\n",
    "os.makedirs(os.path.dirname(MODEL_PATH), exist_ok=True)\n",
    "\n",
    "joblib.dump({\n",
    "    \"model\": champion_model,\n",
    "    \"feature_cols\": feature_cols,\n",
    "    \"numeric_features\": numeric_features,\n",
    "    \"categorical_features\": categorical_features,\n",
    "    \"threshold\": best_threshold,\n",
    "    \"champion_name\": champion_name,\n",
    "}, MODEL_PATH)\n",
    "\n",
    "print(f\"âœ… Champion model artifact saved to: {MODEL_PATH}\")\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
